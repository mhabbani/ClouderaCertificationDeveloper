

sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table orders --target-dir /user/cloudera/problem5/text --fields-terminated-by "\t"

sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table orders --target-dir /user/cloudera/problem5/avro --as-avrodatafile

sqoop import --connect jdbc:mysql://localhost/retail_db --username root --password cloudera --table orders --target-dir /user/cloudera/problem5/parquet --as-parquetfile


import com.databricks.spark.avro._
import sqlContext.implicits._

val avro = sqlContext.read.avro("hdfs:/user/cloudera/problem5/avro")

sqlContext.setConf("spark.sql.parquet.compression.codec","snappy")
avro.write.parquet("hdfs:/user/cludera/problem5/parquet-snappy-compress")



avro.map(x => x(0) + "\t" + x(1) + "\t" + x(2) + "\t" + x(3)).saveAsTextFile("hdfs:/user/cludera/problem5/text-gzip-compress",classOf[org.apache.hadoop.io.compress.GzipCodec])

avro.map(x => (x(0).toString, x(0)+"\t"+x(1)+"\t"+x(2)+"\t"+x(3))).saveAsSequenceFile("hdfs:/user/cludera/problem5/sequence")


avro.map(x => x(0) + "\t" + x(1) + "\t" + x(2) + "\t" + x(3)).saveAsTextFile("hdfs:/user/cludera/problem5/text-snappy1-compress",classOf[org.apache.hadoop.io.compress.SnappyCodec])



val parquet = sqlContext.read.parquet("hdfs:/user/cludera/problem5/parquet-snappy-compress")

sqlContext.setConf("spark.sql.parquet.compression.codec","uncompressed")
parquet.write.parquet("hdfs:/user/cludera/problem5/parquet-no-compress")

sqlContext.setConf("spark.sql.avro.compression.codec","snappy")
parquet.write.avro("hdfs:/user/cludera/problem5/avro-snappy")

val avroSnappy = sqlContext.read.avro("hdfs:/user/cludera/problem5/avro-snappy")

avroSnappy.toJSON.saveAsTextFile("hdfs:/user/cludera/problem5/json-no-compress")
avroSnappy.toJSON.saveAsTextFile("hdfs:/user/cludera/problem5/json-gzip",classOf[org.apache.hadoop.io.compress.GzipCodec])

val json = sqlContext.read.json("hdfs:/user/cludera/problem5/json-gzip")
json.map(x => x(0) + "\t" + x(1) + "\t" + x(2) + "\t" + x(3)).saveAsTextFile("hdfs:/user/cludera/problem5/csv-gzip", classOf[org.apache.hadoop.io.compress.GzipCodec])







